{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK Stop words\n",
    "\n",
    "mylist= ['إذ','إذا','إذما','إذن','أف','أقل','أكثر','ألا','إلا','التي','الذي','الذين','اللاتي','اللائي','اللتان','اللتيا','اللتين','اللذان','اللذين','اللواتي','إلى','إليك','إليكم','إليكما','إليكن','أم','أما','أما','إما','أن','إن','إنا','أنا','أنت','أنتم','أنتما','أنتن','إنما','إنه','أنى','أنى','آه','آها','أو','أولاء','أولئك','أوه','آي','أي','أيها','إي','أين','أين','أينما','إيه','بخ','بس','بعد','بعض','بك','بكم','بكم','بكما','بكن','بل','بلى','بما','بماذا','بمن','بنا','به','بها','بهم','بهما','بهن','بي','بين','بيد','تلك','تلكم','تلكما','ته','تي','تين','تينك','ثم','ثمة','حاشا','حبذا','حتى','حيث','حيثما','حين','خلا','دون','ذا','ذات','ذاك','ذان','ذانك','ذلك','ذلكم','ذلكما','ذلكن','ذه','ذو','ذوا','ذواتا','ذواتي','ذي','ذين','ذينك','ريث','سوف','سوى','شتان','عدا','عسى','عل','على','عليك','عليه','عما','عن','عند','غير','فإذا','فإن','فلا','فمن','في','فيم','فيما','فيه','فيها','قد','كأن','كأنما','كأي','كأين','كذا','كذلك','كل','كلا','كلاهما','كلتا','كلما','كليكما','كليهما','كم','كم','كما','كي','كيت','كيف','كيفما','لا','لاسيما','لدى','لست','لستم','لستما','لستن','لسن','لسنا','لعل','لك','لكم','لكما','لكن','لكنما','لكي','لكيلا','لم','لما','لن','وبما','أنهم','إنهم','فبما','لنا','له','لها','لهم','لهما','لهن','لو','لولا','لوما','لي','لئن','ليت','ليس','ليسا','ليست','ليستا','ليسوا','ما','ماذا','متى','مذ','مع','مما','ممن','من','منه','منها','منذ','مه','مهما','نحن','نحو','نعم','ها','هاتان','هاته','هاتي','هاتين','هاك','هاهنا','هذا','هذان','هذه','هذي','هذين','هكذا','هل','هلا','هم','هما','هن','هنا','هناك','هنالك','هو','هؤلاء','هي','هيا','هيت','هيهات','والذي','والذين','وإذ','وإذا','وإن','ولا','ولكن','ولو','وما','ومن','وهو','يا','هي','أفهي','أوهي','فهي','وهي','لهي','هو','أهو','أوهو','أفهو','فهو','وهو','لهو','ولهو','فلهو','هم','أهم','أفهم','أوهم','بهم','فهم','وهم','لهم','ولهم','فلهم','هن','أهن','أوهن','أفهن','فهن','بهن','وهن','لهن','فلهن','ولهن','هما','فهما','لهما','وهما','بهما','ولبهما','فلبهما','أنت','وأنت','لأنت','فأنت','ولأنت','فلأنت','أنتم','وأنتم','لأنتم','فأنتم','فلأنتم','ولأنتم','أنت','وأنتن','لأنتن','فأنتن','فلأنتن','ولأنتن','أنتما','وأنتما','لأنتما','فأنتما','ولأنتما','فلأنتما','نحن','أفنحن','أونحن','أولنحن','ونحن','فنحن','لنحن','ولنحن','فلنحن','أنا','أأنا','أفأنا','أوأنا','وأنا','لأنا','فأنا','ولأنا','فلأنا','هذا','أهذا','أفهذا','أوهذا','بهذا','وهذا','كهذا','لهذا','فهذا','ولهذا','فلهذا','هذه','أهذه','أفهذه','أوهذه','بهذه','وهذه','كهذه','لهذه','فهذه','ولهذه','فلهذه','هذان','أهذان','أفهذان','أوهذان','بهذين','وهذان','كهذين','لهذين','فهذان','ولهذين','فلهذان','هذين','أهذين','أفهذين','أوهذين','بهذين','وهذين','كهذين','لهذان','فهذين','ولهذين','فلهذين','هؤلاء','أهؤلاء','فهؤلاء','وهؤلاء','ولهؤلاء','وبهؤلاء','أفهؤلاء','أوهؤلاء','لهؤلاء','كهؤلاء','بهؤلاء','أكهؤلاء','هاتان','أهاتان','أفهاتان','أوهاتان','وهاتان','كهاتين','لهاتين','فهاتان','ولهاتين','فلهاتان','هاتين','أهاتين','أفهاتين','أوهاتين','بهاتين','وهاتين','كهاتين','لهاتان','فهاتين','ولهاتين','فلهاتين','الذين','اللذان','الذي','التي','اللذين','اللاتي','اللائي','والذين','واللذان','والذي','والتي','واللذين','واللاتي','واللائي','فالذين','فاللذان','فالذي','فالتي','فاللذين','فاللاتي','فاللائي','كالذين','كاللذان','كالذي','كالتي','كاللذين','كاللاتي','كاللائي','للذين','لللذان','للذي','للتي','للذين','للاتي','للائي','بالذين','باللذان','بالذي','بالتي','باللذين','باللاتي','باللائي','أوالذين','أواللذان','أوالذي','أوالتي','أواللذين','أواللاتي','أواللائي','أفالذين','أفاللذان','أفالذي','أفالتي','أفاللذين','أفاللاتي','أفاللائي','وللذين','ولللذان','وللذي','وللتي','وللذين','وللاتي','وللائي','وبالذين','وباللذان','وبالذي','وبالتي','وباللذين','وباللاتي','وباللائي','ثم','فثمة','وثمة','لم','ولم','فلم','سوف','وسوف','فسوف','أفسوف','أوسوف','ولسوف','أن','إن','إنا','أنا','وأن','وإن','وإنا','وأنا','فأن','فإن','فإنا','فأنا','بأن','بإن','بإنا','بأنا','أوأن','أوإن','أوإنا','أوأنا','ولأن','ولإن','ولإنا','ولأنا','لئن','فلئن','ولئن','أولئن','أفلئن','ما','وما','أفما','أوما','ولما','لما','كلما','فلما','عم','عمن','بما','فما','كما','وكما','فكما','قد','وقد','لقد','فقد','لكن','ولكن','فلكن','لكنهم','ولكنهم','فلكنهم','لكنه','ولكنه','فلكنه','لكنها','ولكنها','فلكنها','لكنهما','ولكنهما','فلكنهما','لكنهن','ولكنهن','فلكنهن','إذا','إذ','فإذا','وإذا','فإذ','وإذ','أو','في','وفي','ففي','لفي','وفي','من','ومن','فمن','لمن','أومن','أفمن','كمن','إلى','وإلى','فإلى','أإلى','إلام','علام','حتام','عن','وعن','فعن','أوعن','طالما','لطالما','فطالما','حاشا','وحاشا','وعدا','إلا','فحاشا','فعدا','وإلا','ألا','كلا','نعم','اللهم','كل','فكل','ككل','ولكل','وككل','وكل','لكل','ولكل','فلكل','بكل','وبكل','فبكل','كلهم','فكلهم','ككلهم','ولكلهم','وككل','وكلهم','لكلهم','ولكلهم','فلكلهم','بكلهما','وبكلهما','فبكلهما','كلهن','فكلهن','ككل','ولكل','وككل','وكلكم','لكلكم','ولكلكم','فلكلكم','بكل','وبكل','فبكل','كلهما','وكلهما','فكلهما','فكلهن','كله','وكله','فكله','بكله','لكله','ككله','كلها','وكلها','بكلها','فكلها','لكلها','ككلها','ولكلها','بعض','ببعض','وببعض','فببعض','وبعض','ولبعض','فلبعض','فبعض','كبعض','وكبعض','بعضها','ببعضها','وببعضها','فببعضها','وبعضها','ولبعضها','فلبعضها','فبعضها','كبعضها','وكبعضها','بعضه','ببعضه','وببعضه','فببعضه','وبعضه','ولبعضه','فلبعضه','فبعضه','كبعضه','وكبعضه','بعضهن','ببعضهن','وببعضهن','فببعضهن','وبعضهن','ولبعضهن','فلبعضهن','فبعضهن','كبعضهن','وكبعضهن','بعضهم','ببعضهم','وببعضهم','فببعضهم','وبعضهم','ولبعضهم','فلبعضهم','فبعضهم','كبعضهم','وكبعضهم','بعضهما','ببعضهما','وببعضهما','فببعضهما','وبعضهما','ولبعضهما','فلبعضهما','فبعضهما','كبعضهما','وكبعضهما','جميع','وجميع','فجميع','لجميع','كجميع','جميعهم','وجميعهم','فجميعهم','بجميع','بجميعهم','جميعهن','وجميعهن','ولجميعهم','بجميعهن','كجميعهن','جميعها','وجميعها','فجميعها','لجميعها','كجميعها','جميعه','وجميعه','فجميعه','لجميعه','كجميعه','إلخ','حيث','وحيث','بحيث','ثم','فثم','فثمة','ليس','وليس','لا','ولا','ألا','إلا','كلا','نعم','بلى','أفلا','أولا','قبل','قبله','قبلها','قبلهن','قبلهم','قبلي','قبلك','قبلكم','قبلهما','قبلكما','وقبل','وقبله','وقبلها','وقبلهن','وقبلهم','وقبلي','وقبلك','وقبلكم','وقبلهما','وقبلكما','فقبل','فقبله','فقبلها','فقبلهن','فقبلهم','فقبلي','فقبلك','فقبلكم','فقبلهما','فقبلكما','ولقبلكما','بعد','بعده','بعدها','بعدهن','بعدهم','بعدي','بعدك','بعدكم','بعدهما','بعدكما','وبعد','وبعده','وبعدها','وبعدهن','وبعدهم','وبعدي','وبعدك','وبعدكم','وبعدهما','وبعدكما','فبعد','فبعده','فبعدها','فبعدهن','فبعدهم','ولبعدهم','فبعدي','فبعدك','فبعدكم','فبعدهما','فبعدكما','ولبعدكما','من','منه','منها','منهما','منكما','منهم','منهن','منك','مني','منكن','ومن','ومنه','ومنها','ومنهما','ومنكما','ومنهم','ومنهن','ومنك','ومني','ومنكن','فمن','فمنه','فمنها','فمنهما','فمنكما','فمنهم','فمنهن','فمنك','فمني','فمنكن','أمن','أمنه','أمنها','أمنهما','أمنكما','أمنهم','أمنهن','أمنك','أمني','أمنكن','عن','عنه','عنها','عنهما','عنكما','عنهم','عنهن','عنك','عني','عنكن','وعن','وعنه','وعنها','وعنهما','وعنكما','وعنهم','وعنهن','وعنك','وعني','وعنكن','فعن','فعنه','فعنها','فعنهما','فعنكما','فعنهم','فعنهن','فعنك','فعني','فعنكن','أعن','أعنه','أعنها','أعنهما','أعنكما','أعنهم'\n",
    "         ,'أعنهن','أعنك','أعني','أعنكن','قد','وقد','فلقد','ولقد','لم','ولم','أولم','فلم','ل','له','لها','لهما','لكما','لهم','لهن','لك','لي','لكن','ول'\n",
    "         ,'وله','ولها','ولهما','ولكما','ولهم','ولهن','ولك','ولي','ولكن','فل','فله','فلها','فلهما','فلكما','فلهم','فلهن','فلك','فلي','فلكن','أل','أله','ألها'\n",
    "         ,'ألهما','ألكما','ألهم','ألهن','ألك','ألي','ألكن','في','فيه','فيها','فيهما','فيكما','فيهم','فيهن','فيك','فيي','فيكن','وفي','وفيه','وفيها','وفيهما'\n",
    "         ,'وفيكما','وفيهم','وفيهن','وفيك','وفيي','وفيكن','ففي','ففيه','ففيها','ففيهما','ففيكما','ففيهم','ففيهن','ففيك','ففيي','ففيكن','أفي','أفيه','أفيها'\n",
    "         ,'أفيهما','أفيكما','أفيهم','أفيهن','أفيك','أفيي','أفيكن','عند','عنده','عندها','عندهما','عندكما','عندهم','عندهن','عندك','عندي','عندكن','وعند'\n",
    "         ,'وعنده','وعندها','وعندهما','وعندكما','وعندهم','وعندهن','وعندك','وعندي','وعندكن','فعند','فعنده','فعندها','فعندهما','فعندكما','فعندهم','فعندهن'\n",
    "         ,'فعندك','فعندي','فعندكن','أعند','أعنده','أعندها','أعندهما','أعندكما','أعندهم','أعندهن','أعندك','أعندي','أعندكن','مع','معه','معها','معهما'\n",
    "         ,'معكما','معهم','معهن','معك','معي','معكن','ومع','ومعه','ومعها','ومعهما','ومعكما','ومعهم','ومعهن','ومعك','ومعي','ومعكن','فمع','فمعه','فمعها','فمعهما','فمعكما','فمعهم','فمعهن','فمعك','فمعي','فمعكن','أمع','أمعه','أمعها','أمعهما','أمعكما','أمعهم','أمعهن','أمعك','أمعي','أمعكن','إلى','إليه','إليها','إليهما','إليكما','إليهم','إليهن','إليك','إليي','إليكن','وإلي','وإليه','وإليها','وإليهما','وإليكما','وإليهم','وإليهن','وإليك','وإليكن','فإلي','فإليه','فإليها','فإليهما','فإليكما','فإليهم','فإليهن','فإليك','فإليي','فإليكن','أإلي','أإليه','أإليها','أإليهما','أإليكما','أإليهم','أإليهن','أإليك','أإليي','أإليكن','على','عليه','عليها','عليهما','عليكما','عليهم','عليهن','عليك','عليكن','وعلى','وعليه','وعليها','وعليهما','وعليكما','وعليهم','وعليهن','وعليك','وعليي','وعليكن','فعلى','فعليه','فعليها','فعليهما','فعليكما','فعليهم','فعليهن','فعليك','فعليي','فعليكن','أعليه','أعليها','أعليهما','أعليكما','أعليهم','أعليهن','أعليك','أعليكن','إياك','فإياك','وإياك','إياكم','فإياكم','وإياكم','إياكن','فإياكن','وإياكن','إياكما','فإياكما','وإياكما','إياكم','فإياكم','وإياكم','إياهم','فإياهم','وإياهم','إياهن','فإياهن','وإياهن','إياي','فإياي','وإياي','إيانا','فإيانا','وإيانا','كذلك','وكذلك','ولذلك','تلكم','وتلكم','وتلكما','فتلكما','ربما','ولربما','فلربما','وربما','لعل','ولعل','فلعل','ليت','وليت','فليت','يا','أو','لو','لولا','ولو','فلو','فلولا','ولولا','ب','به','بها','بهما','بكما','بهم','بهن','بك','بي','بكن','وب','وبه','وبها','وبهما','وبكما','وبهم','وبهن','وبك','وبي','وبكن','فب','فبه','فبها','فبهما','فبكما','فبهم','فبهن','فبك','فبي','فبكن','أبه','أبها','أبهما','أبكما','أبهم','أبهن','أبك','أبي','أبكن','بين','وبين','فبين','لبين','بينه','وبينه','فبينه','لبينه','بينها','بينهما','وبينهما','فبينهما','ولبينهما','لبينهما','وبينهم','فبينهم','ولبينهم','لبينهم','وبينها','فبينها','ولبينها','لبينها','بينهم','بينهن','لبينهن','وبينهن','فبينهن','بيني','وبيني','فبيني','لبيني','بيننا','فبيننا','وبيننا','لبيننا','خلال','خلالهما','خلالهن','خلاله','خلالها','خلالي','خلالك','خلالنا','وخلال','وخلالهما','وخلالهن','وخلاله','وخلالها','وخلالي','وخلالك','وخلالنا','فخلال','فخلالهما','فخلالهن','فخلاله','فخلالها','فخلالي','فخلالك','فخلالنا','تحت','وتحت','فتحت','ولتحت','تحته','وتحته','فتحته','ولتحته','تحتها','وتحتها','فتحتها','ولتحتها','تحتهم','وتحتهم','فتحتهم','ولتحتهم','تحتهن','وتحتهن','فتحتهن','ولتحتهن','تحتي','وتحتي','فتحتي','ولتحتي','تحتهما','وتحتهما','فتحتهما','ولتحتهما','تحتكم','وتحتكم','فتحتكم','ولتحتكم','تحتكن','وتحتكن','فتحتكن','ولتحتكن','تحتكما','وتحتكما','فتحتكما','ولتحتكما','فوق','وفوق','ففوق','ولفوق','فوقه','وفوقه','ففوقه','ولفوقه','فوقها','وفوقها','ففوقها','ولفوقها','فوقهم','وفوقهم','ففوقهم','ولفوقهم','فوقهن','وفوقهن','ففوقهن','ولفوقهن','فوقي','وفوقي','ففوقي','ولفوقي','فوقهما','وفوقهما','ففوقهما','ولفوقهما','فوقكم','وفوقكم','ففوقكم','ولفوقكم','فوقكن','وفوقكن','ففوقكن','ولفوقكن','فوقكما','وفوقكما','ففوقكما','ولفوقكما','أ','ب','ت','ث','ج','ح','خ','د','ذ','ر','ز','س','ش','ص','ض','ط','ظ','ع','غ','ف','ق','ك','ل','م','ن','ه','و','ي','أي','أيهم','أيها','أيهن','أينا','أيكم','أيهم','أيكن','أيهن','وأي','وأيهم','وأيها','وأيهن','وأينا','وأيكم','وأيهم','وأيكن','وأيهن','فأي','فأيهم','فأيها','فأيهن','فأينا','فأيكم','فأيهم','فأيكن','فأيهن','لأي','لأيهم','لأيها','لأيهن','لأينا','لأيكم','لأيهم','لأيكن','لأيهن','كأي','كأيهم','كأيها','كأيهن','كأينا','كأيكم','كأيهم','كأيكن','كأيهن','ذلك','وذلك','فذلك','أذلك','كذلك','بذلك','لذلك','ذلكم','وذلكم','فذلكم','أذلكم','كمذلكم','بذلكم','لذلكم','ذلكن','وذلكن','فذلكن','أذلكن','كنذلكن','بذلكن','لذلكن','ذلكما','وذلكما','فذلكما','أذلكما','كماذلكما','بذلكما','لذلكما','أن','لأن','لأنهم','لأنهما','لأنكم','لأني','لأنكما','لأنكن','لأني','وأن','ولأن','ولأنهم','ولأنهما','ولأنكم','ولأني','ولأنكما','ولأنكن','ولأني','فأن','فلأن','فلأنهم','فلأنهما','فلأنكم','فلأني','فلأنكما','فلأنكن','فلأني','فلئن','ولئن','فلا','لأنه','بل','مما','ذا','كذا','هل','وهل','فهل','أنه','أنها','أنهم','أنهن','أنهما','أنني','أنكم','أننا','وأنه','وأنها','وأنهم','وأنهن','وأنهما','وأنني','وأنكم','وأننا','فأنه','فأنها','فأنهم','فأنهن','فأنهما','فأنني','فأنكم','فأننا','كأنه','كأنها','كأنهم','كأنهن','كأنهما','كأنني','كأنكم','كأننا','لأنه','لأنها','لأنهم','لأنهن','لأنهما','لأنني','لأنكم','لأننا','أني','وأني','فأني','كأني','لنا','ولنا','فلنا','حتى','وحتى','فحتى','فيما','أما','وأما','إنما','أم','وأما','إما','ثنا','حين','وحين','فحين','يومئذ','ويومئذ','فيومئذ','عندئذ','وعندئذ','فعندئذ','إني','هنا','هناك','وهناك','فهناك','لهناك','عما','وعما','وعم','عم','لما','أنى','أيان'\n",
    "         ,'ماذا','لماذا','ولماذا','فلماذا','وعلام','وحتام','طالما','قلما','وطالما','فطالما','وقلما','ذاك','ذينك','تينك','ذينك','ليست','وليست','فليست','أليست'\n",
    "         ,'أوليست','أوليس','فليس','وليس','إنها','بينه','كيف','وكيف','فكيف','لكيف','لن','فلن','ولن','ألن','أنهما','إذن','أن','أوربما','أربما','منذ','كأن'\n",
    "         ,'فإنك','هكذا','وهكذا','فإنه','فإنها','فإنهم','فإنهن','فإنهما','فإنك','فإنهما','فإنكما','فإنكم','فإني','فإنني','الا','اذا','اذ','الى','فى','آل','الدكتور'\n",
    "         ,'السعودية','العربية','عبدالله','سعود','خلال','متي','ومتى','متى','فمتى','فأيان','كمن','فيمن','فأما','نا','ثنا','ومما'\n",
    "         ,'فإننا','فإنا','كان','فكان','وكان','يكون','كانوا','كنا','كنتم','وكنتم','فكنا','وكنا','لكنا','ولكنا','كنت','وكنت','وعندنا','عندنا','اه','أنى','عا'\n",
    "         ,'انه','انها','كذا','وكذا','فكذا','ال','وهكذا','ؤ','ء','لآ','آ','ا','ئ','ة','لإ','ى','هكذا','لهذا','فلهذا','ولهذا','كانت','إذا','إذما','إذن'\n",
    "         ,'أف','أقل','أكثر','ألا','إلا','التي','الذي','الذين','اللاتي','اللائي','اللتان','اللتيا','اللتين','اللذان','اللذين','اللواتي','إلى','إليك','إليكم','إليكما'\n",
    "         ,'إليكن','أم','أما','أما','إما','أن','إن','إنا','أنا','أنت','أنتم','أنتما','أنتن','إنما','إنه','أنى','أنى','آه','آها','أو','أولاء','أولئك','أوه'\n",
    "         ,'آي','أي','أيها','إي','أين','أين','أينما','إيه','بخ','بس','بعد','بعض','بك','بكم','بكم','بكما','بكن','بل','بلى','بما','بماذا','بمن','بنا','عدد','تم','كورونا','العام'\n",
    "         ,'به','بها','بهم','بهما','بهن','بي','بين','بيد','تلك','تلكم','تلكما','ته','تي','تين','تينك','ثم','ثمة','حاشا','حبذا','حتى','حيث','حيثما'\n",
    "         ,'حين','خلا','دون','ذا','ذات','ذاك','ذان','ذانك','ذلك','ذلكم','ذلكما','ذلكن','ذه','ذو','ذوا','ذواتا','ذواتي','ذي','ذين','ذينك','ريث'\n",
    "         ,'سوف','سوى','شتان','عدا','عسى','عل','على','عليك','عليه','عما','عن','عند','غير','فإذا','فإن','فلا','فمن','في','فيم','فيما','فيه'\n",
    "         ,'فيها','قد','كأن','كأنما','كأي','كأين','كذا','كذلك','كل','كلا','كلاهما','كلتا','كلما','كليكما','كليهما','كم','كم','كما','كي','كيت','كيف'\n",
    "         ,'كيفما','لا','لاسيما','لدى','لست','لستم','لستما','لستن','لسن','لسنا','لعل','لك','لكم','لكما','لكن','لكنما','لكي','لكيلا','لم','لما','لن','لنا','له'\n",
    "         ,'لها','لهم','لهما','لهن','لو','لولا','لوما','لي','لئن','ليت','ليس','ليسا','ليست','ليستا','ليسوا','ما','ماذا','متى','مذ','مع','مما','ممن','من'\n",
    "         ,'منه','منها','منذ','مه','مهما','نحن','نحو','نعم','ها','هاتان','هاته','هاتي','هاتين','هاك','هاهنا','هذا','هذان','هذه','هذي','هذين','هكذا'\n",
    "         ,'هل','هلا','هم','هما','هن','هنا','هناك','هنالك','هو','هؤلاء','هي','هيا','هيت','هيهات','والذي','فكانت','وإذ','وإذا','وإن','ولا','ولكن','يمكن','يتم','يجب','حول'\n",
    "         ,'ولو','وما','ومن','وهو','يا','إذما','إذما','إذما','إذما','والذين','تكون','ان','ولكنتما','وكانتا','فكانتا','كانتا','فكنتم','فكنا','فكن','وكن','كن','وزير','الدكتور','خالد','فيصل','وقال','قال','عبر','فقط'\n",
    "         ,'يكن','لتكن','ولتكن','فلتكن','ولكانت','لكانت','وان','كونوا','كنتما','عندما','الله','بن']\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = mylist\n",
    "#stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>العصر</th>\n",
       "      <th>الشاعر</th>\n",
       "      <th>الديوان</th>\n",
       "      <th>القافية</th>\n",
       "      <th>البحر</th>\n",
       "      <th>الشطر الايسر</th>\n",
       "      <th>الشطر الايمن</th>\n",
       "      <th>البيت</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>قبل الإسلام</td>\n",
       "      <td>عمرو بنِ قُمَيئَة</td>\n",
       "      <td>الديوان الرئيسي</td>\n",
       "      <td>د</td>\n",
       "      <td>الطويل</td>\n",
       "      <td>وَأَن تَجمَعا شَملي وَتَنتَظِرا غَدا</td>\n",
       "      <td>خَليلَيَّ لا تَستَعجِلا أَن تَزَوَّدا</td>\n",
       "      <td>خَليلَيَّ لا تَستَعجِلا أَن تَزَوَّدا    وَأَن...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>قبل الإسلام</td>\n",
       "      <td>عمرو بنِ قُمَيئَة</td>\n",
       "      <td>الديوان الرئيسي</td>\n",
       "      <td>د</td>\n",
       "      <td>الطويل</td>\n",
       "      <td>وَلا سُرعَتي يَوماً بِسابِقَةِ الرَدى</td>\n",
       "      <td>فَما لَبَثٌ يَوماً بِسابِقٍ مَغنَمٍ</td>\n",
       "      <td>فَما لَبَثٌ يَوماً بِسابِقٍ مَغنَمٍ    وَلا سُ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>قبل الإسلام</td>\n",
       "      <td>عمرو بنِ قُمَيئَة</td>\n",
       "      <td>الديوان الرئيسي</td>\n",
       "      <td>د</td>\n",
       "      <td>الطويل</td>\n",
       "      <td>وَتَستَوجِبا مَنّاً عَلَيَّ وَتُحمَدا</td>\n",
       "      <td>وَإِن تُنظِراني اليَومَ أَقضِ لُبانَةً</td>\n",
       "      <td>وَإِن تُنظِراني اليَومَ أَقضِ لُبانَةً    وَتَ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>قبل الإسلام</td>\n",
       "      <td>عمرو بنِ قُمَيئَة</td>\n",
       "      <td>الديوان الرئيسي</td>\n",
       "      <td>د</td>\n",
       "      <td>الطويل</td>\n",
       "      <td>تُؤامِرُني سِرّاً لِأَصرِمَ مَرثَدا</td>\n",
       "      <td>لَعَمرُكَ ما نَفسٌ بِجِدٍ رَشيدَةٍ</td>\n",
       "      <td>لَعَمرُكَ ما نَفسٌ بِجِدٍ رَشيدَةٍ    تُؤامِرُ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>قبل الإسلام</td>\n",
       "      <td>عمرو بنِ قُمَيئَة</td>\n",
       "      <td>الديوان الرئيسي</td>\n",
       "      <td>د</td>\n",
       "      <td>الطويل</td>\n",
       "      <td>وَأَفرَعَ في لَومي مِراراً وَأَصعَدا</td>\n",
       "      <td>وَإِن ظَهَرَت مِنهُ قَوارِصُ جَمَّةٌ</td>\n",
       "      <td>وَإِن ظَهَرَت مِنهُ قَوارِصُ جَمَّةٌ    وَأَفر...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684663</th>\n",
       "      <td>1831765</td>\n",
       "      <td>1831765</td>\n",
       "      <td>الحديث</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>ن</td>\n",
       "      <td>الخفيف</td>\n",
       "      <td>وأحلى قصيدة تَتَغنى</td>\n",
       "      <td>هي أغلى ما أنشأ اللَّه في الدنيا</td>\n",
       "      <td>هي أغلى ما أنشأ اللَّه في الدنيا    وأحلى قصيد...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684664</th>\n",
       "      <td>1831766</td>\n",
       "      <td>1831766</td>\n",
       "      <td>الحديث</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>ن</td>\n",
       "      <td>الخفيف</td>\n",
       "      <td>كحلم يغشى الجفون الوسنى</td>\n",
       "      <td>هي أغرودة الأغاريد تنساب</td>\n",
       "      <td>هي أغرودة الأغاريد تنساب    كحلم يغشى الجفون ا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684665</th>\n",
       "      <td>1831767</td>\n",
       "      <td>1831767</td>\n",
       "      <td>الحديث</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>ن</td>\n",
       "      <td>الخفيف</td>\n",
       "      <td>يتداعى وجداً ويخفق حسنا</td>\n",
       "      <td>هي شلال بهجة وبهاء</td>\n",
       "      <td>هي شلال بهجة وبهاء    يتداعى وجداً ويخفق حسنا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684666</th>\n",
       "      <td>1831768</td>\n",
       "      <td>1831768</td>\n",
       "      <td>الحديث</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>ن</td>\n",
       "      <td>الخفيف</td>\n",
       "      <td>يدك الحدود سجناً فسجنا</td>\n",
       "      <td>هي حلم الهوى ومنطلقي الباقي</td>\n",
       "      <td>هي حلم الهوى ومنطلقي الباقي    يدك الحدود سجنا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684667</th>\n",
       "      <td>1831769</td>\n",
       "      <td>1831769</td>\n",
       "      <td>الحديث</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>شهاب غانم</td>\n",
       "      <td>ن</td>\n",
       "      <td>الخفيف</td>\n",
       "      <td>آه لو أدرك الغرام لجنا</td>\n",
       "      <td>هي حبي العاتي وكل غرامي</td>\n",
       "      <td>هي حبي العاتي وكل غرامي    آه لو أدرك الغرام لجنا</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1684668 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  Unnamed: 0.1        العصر             الشاعر  \\\n",
       "0                 0             0  قبل الإسلام  عمرو بنِ قُمَيئَة   \n",
       "1                 1             1  قبل الإسلام  عمرو بنِ قُمَيئَة   \n",
       "2                 2             2  قبل الإسلام  عمرو بنِ قُمَيئَة   \n",
       "3                 3             3  قبل الإسلام  عمرو بنِ قُمَيئَة   \n",
       "4                 4             4  قبل الإسلام  عمرو بنِ قُمَيئَة   \n",
       "...             ...           ...          ...                ...   \n",
       "1684663     1831765       1831765       الحديث          شهاب غانم   \n",
       "1684664     1831766       1831766       الحديث          شهاب غانم   \n",
       "1684665     1831767       1831767       الحديث          شهاب غانم   \n",
       "1684666     1831768       1831768       الحديث          شهاب غانم   \n",
       "1684667     1831769       1831769       الحديث          شهاب غانم   \n",
       "\n",
       "                 الديوان القافية   البحر  \\\n",
       "0        الديوان الرئيسي       د  الطويل   \n",
       "1        الديوان الرئيسي       د  الطويل   \n",
       "2        الديوان الرئيسي       د  الطويل   \n",
       "3        الديوان الرئيسي       د  الطويل   \n",
       "4        الديوان الرئيسي       د  الطويل   \n",
       "...                  ...     ...     ...   \n",
       "1684663        شهاب غانم       ن  الخفيف   \n",
       "1684664        شهاب غانم       ن  الخفيف   \n",
       "1684665        شهاب غانم       ن  الخفيف   \n",
       "1684666        شهاب غانم       ن  الخفيف   \n",
       "1684667        شهاب غانم       ن  الخفيف   \n",
       "\n",
       "                                  الشطر الايسر  \\\n",
       "0         وَأَن تَجمَعا شَملي وَتَنتَظِرا غَدا   \n",
       "1        وَلا سُرعَتي يَوماً بِسابِقَةِ الرَدى   \n",
       "2        وَتَستَوجِبا مَنّاً عَلَيَّ وَتُحمَدا   \n",
       "3          تُؤامِرُني سِرّاً لِأَصرِمَ مَرثَدا   \n",
       "4         وَأَفرَعَ في لَومي مِراراً وَأَصعَدا   \n",
       "...                                        ...   \n",
       "1684663                    وأحلى قصيدة تَتَغنى   \n",
       "1684664                كحلم يغشى الجفون الوسنى   \n",
       "1684665                يتداعى وجداً ويخفق حسنا   \n",
       "1684666                 يدك الحدود سجناً فسجنا   \n",
       "1684667                 آه لو أدرك الغرام لجنا   \n",
       "\n",
       "                                   الشطر الايمن  \\\n",
       "0         خَليلَيَّ لا تَستَعجِلا أَن تَزَوَّدا   \n",
       "1           فَما لَبَثٌ يَوماً بِسابِقٍ مَغنَمٍ   \n",
       "2        وَإِن تُنظِراني اليَومَ أَقضِ لُبانَةً   \n",
       "3            لَعَمرُكَ ما نَفسٌ بِجِدٍ رَشيدَةٍ   \n",
       "4          وَإِن ظَهَرَت مِنهُ قَوارِصُ جَمَّةٌ   \n",
       "...                                         ...   \n",
       "1684663        هي أغلى ما أنشأ اللَّه في الدنيا   \n",
       "1684664                هي أغرودة الأغاريد تنساب   \n",
       "1684665                      هي شلال بهجة وبهاء   \n",
       "1684666             هي حلم الهوى ومنطلقي الباقي   \n",
       "1684667                 هي حبي العاتي وكل غرامي   \n",
       "\n",
       "                                                     البيت  \n",
       "0        خَليلَيَّ لا تَستَعجِلا أَن تَزَوَّدا    وَأَن...  \n",
       "1        فَما لَبَثٌ يَوماً بِسابِقٍ مَغنَمٍ    وَلا سُ...  \n",
       "2        وَإِن تُنظِراني اليَومَ أَقضِ لُبانَةً    وَتَ...  \n",
       "3        لَعَمرُكَ ما نَفسٌ بِجِدٍ رَشيدَةٍ    تُؤامِرُ...  \n",
       "4        وَإِن ظَهَرَت مِنهُ قَوارِصُ جَمَّةٌ    وَأَفر...  \n",
       "...                                                    ...  \n",
       "1684663  هي أغلى ما أنشأ اللَّه في الدنيا    وأحلى قصيد...  \n",
       "1684664  هي أغرودة الأغاريد تنساب    كحلم يغشى الجفون ا...  \n",
       "1684665      هي شلال بهجة وبهاء    يتداعى وجداً ويخفق حسنا  \n",
       "1684666  هي حلم الهوى ومنطلقي الباقي    يدك الحدود سجنا...  \n",
       "1684667  هي حبي العاتي وكل غرامي    آه لو أدرك الغرام لجنا  \n",
       "\n",
       "[1684668 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\\\Users\\\\HP\\\\Downloads\\\\clean_Arabic_Poem Comprehensive_Dataset.csv')\n",
    "df.drop(columns=to_drop, inplace=True)\n",
    "del df[\"a\"]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1684668"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['خَليلَيَّ لا تَستَعجِلا أَن تَزَوَّدا وَأَن تَجمَعا شَملي وَتَنتَظِرا غَدا']\n"
     ]
    }
   ],
   "source": [
    "# Convert to list\n",
    "data = df.البيت.values.tolist()\n",
    "#data = df.fullText.values.tolist()\n",
    "\n",
    "# Remove Emails\n",
    "data = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in data]\n",
    "\n",
    "# Remove new line characters\n",
    "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "\n",
    "# Remove distracting single quotes\n",
    "data = [re.sub(\"\\'\", \"\", sent) for sent in data]\n",
    "\n",
    "pprint(data[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['خليلي', 'لا', 'تستعجلا', 'ان', 'تزودا', 'وان', 'تجمعا', 'شملي', 'وتنتظرا', 'غدا']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['خليلي', 'لا', 'تستعجلا', 'ان', 'تزودا', 'وان', 'تجمعا', 'شملي', 'وتنتظرا', 'غدا']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in mylist] for doc in texts]\n",
    "\n",
    "#def make_bigrams(texts):\n",
    "   # return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "#def make_trigrams(texts):\n",
    " #   return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['خليلي', 'تستعجلا', 'تزودا', 'تجمعا', 'شملي', 'وتنتظرا', 'غدا']]\n"
     ]
    }
   ],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "#data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "#data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "#print(data_lemmatized[:1])\n",
    "print(data_words_nostops[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_words_nostops)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_words_nostops\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('تجمعا', 1),\n",
       "  ('تزودا', 1),\n",
       "  ('تستعجلا', 1),\n",
       "  ('خليلي', 1),\n",
       "  ('شملي', 1),\n",
       "  ('غدا', 1),\n",
       "  ('وتنتظرا', 1)],\n",
       " [('الردى', 1),\n",
       "  ('بسابق', 1),\n",
       "  ('بسابقة', 1),\n",
       "  ('سرعتي', 1),\n",
       "  ('لبث', 1),\n",
       "  ('مغنم', 1),\n",
       "  ('يوما', 2)],\n",
       " [('اقض', 1),\n",
       "  ('اليوم', 1),\n",
       "  ('تنظراني', 1),\n",
       "  ('علي', 1),\n",
       "  ('لبانة', 1),\n",
       "  ('منا', 1),\n",
       "  ('وتحمدا', 1),\n",
       "  ('وتستوجبا', 1)],\n",
       " [('بجد', 1),\n",
       "  ('توامرني', 1),\n",
       "  ('رشيدة', 1),\n",
       "  ('سرا', 1),\n",
       "  ('لاصرم', 1),\n",
       "  ('لعمرك', 1),\n",
       "  ('مرثدا', 1),\n",
       "  ('نفس', 1)]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Human readable format of corpus (term-frequency)\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=8, \n",
    "                                           random_state=50,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=.1,\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "print(lda_model.print_topics())\n",
    "#print(\"$\")\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_words_nostops, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word, mds='tsne')\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ.update({'MALLET_HOME':r'C:\\\\Users\\\\HP\\\\AppData\\\\Local\\\\Temp\\\\mallet-2.0.8\\\\mallet-2.0.8'})\n",
    "mallet_path = 'C:\\\\Users\\\\HP\\\\AppData\\\\Local\\\\Temp\\\\mallet-2.0.8\\\\mallet-2.0.8\\\\bin\\\\mallet' # update this path\n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=2, id2word=id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Topics\n",
    "#print(ldamallet.show_topics(formatted=True))\n",
    "print(ldamallet.show_topics(2))\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_words_nostops, dictionary=id2word, coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_ldamallet)\n",
    "\n",
    "# Compute Coherence Score using UMass\n",
    "#coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_words_nostops, dictionary=id2word, coherence=\"u_mass\")\n",
    "#coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "#print('\\nCoherence Score: ', coherence_ldamallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=1, step=1):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Can take a long time to run.\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_words_nostops, start=1,limit=10, step=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib \n",
    "matplotlib.rc('xtick', labelsize=12) \n",
    "matplotlib.rc('ytick', labelsize=12)\n",
    "\n",
    "font = {'family' : 'sakkal majalla',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 16}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "from arabic_reshaper import arabic_reshaper\n",
    "from bidi.algorithm import get_display\n",
    "from matplotlib import pyplot as plt\n",
    "def f(x):\n",
    "    out=get_display(arabic_reshaper.reshape(x))\n",
    "    return(out)\n",
    "# Show graph\n",
    "limit=10; start=1; step=1;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(f(\"عدد الموضوعات\"), alpha = 1)\n",
    "plt.ylabel(f(\"درجة التماسك\"), alpha = 1)\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the model and print the topics\n",
    "optimal_model = model_list[6]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "print(optimal_model.print_topics(num_words=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=data)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group top 5 sentences under each topic\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Documents for Each Topic\n",
    "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
    "\n",
    "# Percentage of Documents for Each Topic\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "\n",
    "# Topic Number and Keywords\n",
    "topic_num_keywords = df_topic_sents_keywords[['Dominant_Topic', 'Topic_Keywords']]\n",
    "\n",
    "# Concatenate Column wise\n",
    "df_dominant_topics = pd.concat([topic_num_keywords, topic_counts, topic_contribution], axis=1)\n",
    "\n",
    "# Change Column names\n",
    "df_dominant_topics.columns = ['Dominant_Topic', 'Topic_Keywords', 'Num_Documents', 'Perc_Documents']\n",
    "\n",
    "# Show\n",
    "df_dominant_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
